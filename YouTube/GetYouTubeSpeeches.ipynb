{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from pytube import Playlist\n",
    "from pytube import YouTube\n",
    "import pandas as pd\n",
    "import datefinder\n",
    "import urllib\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download videos\n",
    "## Useful documentation: https://pytube.io/en/latest/api.html#youtube-object\n",
    "def download_360p_mp4_videos(url: str, path: str):\n",
    "    yt = YouTube(url)\n",
    "    yt.streams.filter(file_extension=\"mp4\").get_by_resolution(\"360p\").download(filename=path)\n",
    "\n",
    "def download_videos(playlist_url, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    playlist = Playlist(playlist_url)\n",
    "    print('Number of videos in playlist: %s' % len(playlist.video_urls))\n",
    "    df = pd.DataFrame()\n",
    "    count = 1\n",
    "    for url in playlist.video_urls:\n",
    "        filename = \"video_\" + str(count) + \".mp4\"\n",
    "        if not os.path.exists(\"./\" + output_dir + \"/\" + filename):\n",
    "            try:\n",
    "                download_360p_mp4_videos(url, \"./\" + output_dir + \"/video_\" + str(count) + \".mp4\")\n",
    "            except urllib.error.HTTPError:\n",
    "                print(\"ERROR CAUGHT\")\n",
    "                time.sleep(20)\n",
    "                download_360p_mp4_videos(url, \"./\" + output_dir + \"/video_\" + str(count) + \".mp4\")\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(\"DONE\", count)\n",
    "            # time.sleep(4)\n",
    "\n",
    "## Download metadata\n",
    "def get_playlist_metadata(playlist_url, csv_filename, output_dir):\n",
    "    transcriptions_output_dir = output_dir + \"/Transcriptions\"\n",
    "    if not os.path.exists(transcriptions_output_dir):\n",
    "        os.mkdir(transcriptions_output_dir)\n",
    "    playlist = Playlist(playlist_url)\n",
    "\n",
    "    print('Number of videos in playlist: %s' % len(playlist.video_urls))\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    if os.path.exists(csv_filename):\n",
    "        df = pd.read_csv(csv_filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\"video_filename\",\n",
    "                                    \"url\",\n",
    "                                    \"title\",\n",
    "                                    \"length_seconds\",\n",
    "                                    \"publish_date\",\n",
    "                                    \"description\",\n",
    "                                    \"keywords\",\n",
    "                                    \"date\",\n",
    "                                    \"date_src\",\n",
    "                                    \"transcription_filename\"])\n",
    "\n",
    "    count = 1\n",
    "    for url in playlist.video_urls:\n",
    "        filename = \"video_\" + str(count) + \".mp4\"\n",
    "\n",
    "        if filename not in df[\"video_filename\"].tolist():\n",
    "            video = YouTube(url)\n",
    "            filename = \"video_\" + str(count) + \".mp4\"\n",
    "\n",
    "            date = \"\"\n",
    "            date_src = \"\"\n",
    "            title = video.title\n",
    "            description = video.description\n",
    "            if \"Streamed live on \" in video.watch_html:\n",
    "                date_tmp = video.watch_html.split(\"Streamed live on \")[1].split('\"')[0]\n",
    "                matches = datefinder.find_dates(date_tmp)\n",
    "                for match in matches:\n",
    "                    date = match.strftime(\"%d.%m.%Y\")\n",
    "                    date_src = \"live_stream\"\n",
    "            elif (match := re.search(r'\\d\\d\\.\\d\\d\\.\\d\\d\\d\\d', title)) is not None:\n",
    "                date = match.group()\n",
    "                date_src = \"title\"\n",
    "            elif (match := re.search(r'\\d\\d\\.\\d\\d\\.\\d\\d\\d\\d', description)) is not None:\n",
    "                date = match.group()\n",
    "                date_src = \"description\"\n",
    "\n",
    "            transcription_filename = \"\"\n",
    "            if 'a.tr' in video.captions.keys():\n",
    "                soup = BeautifulSoup(video.captions['a.tr'].xml_captions, 'xml')\n",
    "                transcriptions = \"\"\n",
    "                for s in soup.find_all('s'):\n",
    "                    transcriptions += s.text\n",
    "                transcription_filename = \"transcription_\" + str(count) + \".txt\"\n",
    "                text_file = open(transcriptions_output_dir + '/' + transcription_filename, \"w\", encoding=\"utf-8\")\n",
    "                n = text_file.write(transcriptions)\n",
    "                text_file.close()\n",
    "            \n",
    "            new_row = { 'video_filename': filename,\n",
    "                        'url': url,\n",
    "                        'title': title,\n",
    "                        'length_seconds': video.length,\n",
    "                        'publish_date': video.publish_date,\n",
    "                        'description': description,\n",
    "                        'keywords': video.keywords,\n",
    "                        'date': date,\n",
    "                        'date_src': date_src,\n",
    "                        'transcription_filename': transcription_filename}\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame.from_records([new_row])])\n",
    "\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(\"DONE\", count)\n",
    "            # time.sleep(4)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist url: https://www.youtube.com/playlist?list=PLl6P5vAyfWLx0unQuNRmywX7y_5L80eTQ\n",
      "Total hours: 39.1225\n",
      "Number of videos in playlist: 70\n",
      "Estimated cost: 56.544000000000004\n",
      "Playlist url: https://www.youtube.com/playlist?list=PLl6P5vAyfWLweGmJHzAXsyS7xhKR2RYgt\n",
      "Total hours: 323.8594444444444\n",
      "Number of videos in playlist: 619\n",
      "Estimated cost: 468.11400000000003\n"
     ]
    }
   ],
   "source": [
    "## GCP pricing calculator: https://cloud.google.com/products/calculator\n",
    "def estimate_playlist_transcription_cost(playlist_url):\n",
    "    playlist = Playlist(playlist_url)\n",
    "    print(\"Playlist url:\", playlist_url)\n",
    "    sum_fifteen_sec_intervals = 0\n",
    "    count = 0\n",
    "    sum_seconds_total = 0\n",
    "    for video in playlist.videos:\n",
    "        if video.length/60 < 5:\n",
    "            continue\n",
    "        count += 1\n",
    "        sum_seconds_total += video.length\n",
    "        sum_fifteen_sec_intervals += math.ceil(video.length/15)\n",
    "    print('Total hours:', sum_seconds_total/3600)\n",
    "    print('Number of videos in playlist:', count)\n",
    "\n",
    "    print(\"Estimated cost:\", sum_fifteen_sec_intervals * 0.006)\n",
    "# estimate_playlist_transcription_cost(\"https://www.youtube.com/playlist?list=PLIoZEdpULeHk1BDS_U6XF-6yPgj3lNndB\")\n",
    "estimate_playlist_transcription_cost(\"https://www.youtube.com/playlist?list=PLl6P5vAyfWLx0unQuNRmywX7y_5L80eTQ\")\n",
    "estimate_playlist_transcription_cost(\"https://www.youtube.com/playlist?list=PLl6P5vAyfWLweGmJHzAXsyS7xhKR2RYgt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in playlist: 765\n",
      "DONE 50\n",
      "DONE 100\n",
      "DONE 150\n",
      "DONE 200\n",
      "DONE 250\n",
      "DONE 300\n",
      "DONE 350\n",
      "DONE 400\n",
      "DONE 450\n",
      "DONE 500\n",
      "DONE 550\n",
      "DONE 600\n",
      "DONE 650\n",
      "DONE 700\n",
      "DONE 750\n",
      "Number of videos in playlist: 765\n",
      "DONE 10\n",
      "DONE 20\n",
      "DONE 30\n",
      "DONE 40\n",
      "DONE 50\n",
      "DONE 60\n",
      "DONE 70\n",
      "DONE 80\n",
      "DONE 90\n",
      "DONE 100\n",
      "DONE 110\n",
      "DONE 120\n",
      "DONE 130\n",
      "DONE 140\n",
      "DONE 150\n",
      "DONE 160\n",
      "DONE 170\n",
      "DONE 180\n",
      "DONE 190\n",
      "DONE 200\n",
      "DONE 210\n",
      "DONE 220\n",
      "DONE 230\n",
      "DONE 240\n",
      "DONE 250\n",
      "DONE 260\n",
      "DONE 270\n",
      "DONE 280\n",
      "DONE 290\n",
      "DONE 300\n",
      "DONE 310\n",
      "DONE 320\n",
      "DONE 330\n",
      "DONE 340\n",
      "DONE 350\n",
      "DONE 360\n",
      "DONE 370\n",
      "DONE 380\n",
      "DONE 390\n",
      "DONE 400\n",
      "DONE 410\n",
      "DONE 420\n",
      "DONE 430\n",
      "DONE 440\n",
      "DONE 450\n",
      "DONE 460\n",
      "DONE 470\n",
      "DONE 480\n",
      "DONE 490\n",
      "DONE 500\n",
      "DONE 510\n",
      "DONE 520\n",
      "DONE 530\n",
      "DONE 540\n",
      "DONE 550\n",
      "DONE 560\n",
      "DONE 570\n",
      "DONE 580\n",
      "DONE 590\n",
      "DONE 600\n",
      "DONE 610\n",
      "DONE 620\n",
      "DONE 630\n",
      "DONE 640\n",
      "DONE 650\n",
      "DONE 660\n",
      "DONE 670\n",
      "DONE 680\n",
      "DONE 690\n",
      "DONE 700\n",
      "DONE 710\n",
      "DONE 720\n",
      "DONE 730\n",
      "DONE 740\n",
      "DONE 750\n",
      "DONE 760\n"
     ]
    }
   ],
   "source": [
    "playlist_url = 'https://www.youtube.com/playlist?list=PLl6P5vAyfWLweGmJHzAXsyS7xhKR2RYgt'\n",
    "csv_filename = \"akp_playlist_videos2.csv\"\n",
    "output_dir = \"Videos2\"\n",
    "download_videos(playlist_url, output_dir)\n",
    "get_playlist_metadata(playlist_url, csv_filename, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in playlist: 85\n",
      "DONE 10\n",
      "DONE 20\n",
      "DONE 30\n",
      "DONE 40\n",
      "DONE 50\n",
      "ERROR CAUGHT\n",
      "ERROR CAUGHT\n",
      "DONE 60\n",
      "ERROR CAUGHT\n",
      "DONE 70\n",
      "ERROR CAUGHT\n",
      "DONE 80\n",
      "ERROR CAUGHT\n",
      "Number of videos in playlist: 85\n",
      "DONE 50\n"
     ]
    }
   ],
   "source": [
    "playlist_url = 'https://www.youtube.com/playlist?list=PLl6P5vAyfWLx0unQuNRmywX7y_5L80eTQ'\n",
    "csv_filename = \"akp_playlist_videos3.csv\"\n",
    "output_dir = \"Videos3\"\n",
    "download_videos(playlist_url, output_dir)\n",
    "get_playlist_metadata(playlist_url, csv_filename, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in playlist: 682\n",
      "DONE 10\n",
      "DONE 20\n",
      "DONE 30\n"
     ]
    }
   ],
   "source": [
    "playlist_url = \"https://www.youtube.com/playlist?list=PLIoZEdpULeHkUAbidMGMJmquL5lQ3GyAJ\"\n",
    "csv_filename = \"akp_playlist_videos4.csv\"\n",
    "output_dir = \"Videos4\"\n",
    "download_videos(playlist_url, output_dir)\n",
    "get_playlist_metadata(playlist_url, csv_filename, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in playlist: 213\n",
      "DONE 10\n",
      "DONE 20\n",
      "DONE 30\n",
      "DONE 40\n",
      "DONE 50\n",
      "DONE 60\n",
      "DONE 70\n",
      "DONE 80\n",
      "DONE 90\n",
      "DONE 100\n",
      "DONE 110\n",
      "DONE 120\n",
      "DONE 130\n",
      "DONE 140\n",
      "DONE 150\n",
      "DONE 160\n",
      "DONE 170\n",
      "DONE 180\n",
      "ERROR CAUGHT\n",
      "ERROR CAUGHT\n",
      "DONE 190\n",
      "DONE 200\n",
      "DONE 210\n",
      "Number of videos in playlist: 213\n",
      "DONE 10\n",
      "DONE 20\n",
      "DONE 30\n",
      "DONE 40\n",
      "DONE 50\n",
      "DONE 60\n",
      "DONE 70\n",
      "DONE 80\n",
      "DONE 90\n",
      "DONE 100\n",
      "DONE 110\n",
      "DONE 120\n",
      "DONE 130\n",
      "DONE 140\n",
      "DONE 150\n",
      "DONE 160\n",
      "DONE 170\n",
      "DONE 180\n",
      "DONE 190\n",
      "DONE 200\n",
      "DONE 210\n"
     ]
    }
   ],
   "source": [
    "playlist_url = \"https://www.youtube.com/playlist?list=PLIoZEdpULeHk1BDS_U6XF-6yPgj3lNndB\"\n",
    "csv_filename = \"akp_playlist_videos1.csv\"\n",
    "output_dir = \"Videos1\"\n",
    "download_videos(playlist_url, output_dir)\n",
    "get_playlist_metadata(playlist_url, csv_filename, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n",
      "956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NaN            705\n",
       "tccb_videos    461\n",
       "live_stream    420\n",
       "title           47\n",
       "description     28\n",
       "Name: date_src, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"akp_playlist_videos1.csv\")\n",
    "df2 = pd.read_csv(\"akp_playlist_videos2.csv\")\n",
    "df3 = pd.read_csv(\"akp_playlist_videos3.csv\")\n",
    "df4 = pd.read_csv(\"akp_playlist_videos4.csv\")\n",
    "\n",
    "df1 = df1[df1.title.str.contains(\"ErdoÄŸan\")]\n",
    "\n",
    "df1[\"folder\"] = \"Videos1\"\n",
    "df2[\"folder\"] = \"Videos2\"\n",
    "df3[\"folder\"] = \"Videos3\"\n",
    "df4[\"folder\"] = \"Videos4\"\n",
    "\n",
    "new_df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "df_with_dates = pd.read_csv(\"../PresSpeeches/PresVideoLinks.csv\")\n",
    "list_of_videos = df_with_dates[\"title\"].tolist()\n",
    "\n",
    "for index, row in new_df.iterrows():\n",
    "    if not isinstance(row[\"date\"], str):\n",
    "        if len(df_with_dates.loc[df_with_dates['title'] == row[\"title\"]]) > 0:\n",
    "            date_list = row[\"publish_date\"][:10].split(\"-\")\n",
    "            year, month, day = date_list[0], date_list[1], date_list[2]\n",
    "            published_date = day + \".\" + month + \".\" + year\n",
    "\n",
    "            rows = df_with_dates.loc[df_with_dates['title'] == row[\"title\"]]\n",
    "            for i, r in rows.iterrows():\n",
    "                # if r[\"date\"] == published_date:\n",
    "                #     df.at[index,'date']= r [\"date\"]\n",
    "                #     df.at[index,'date_src'] = \"tccb_videos\"\n",
    "                if r[\"date\"][-7:] == published_date[-7:]:\n",
    "                    new_df.at[index,'date'] = r[\"date\"]\n",
    "                    new_df.at[index,'date_src'] = \"tccb_videos\"\n",
    "\n",
    "print(new_df[\"date\"].isnull().sum())\n",
    "print(len(new_df[\"date\"]) - new_df[\"date\"].isnull().sum())\n",
    "\n",
    "new_df.to_csv(\"aggregated_videos.csv\", index = False)\n",
    "new_df[\"date_src\"].value_counts(dropna=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
